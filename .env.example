# API Settings
APP_NAME=Sahabat-9B API
APP_VERSION=1.0.0
API_PREFIX=/api/v1
DEBUG=false

# Server Settings
HOST=0.0.0.0
PORT=8000
WORKERS=1

# Model Settings
MODEL_NAME=Sahabat-AI/gemma2-9b-cpt-sahabatai-v1-instruct
MODEL_MAX_LENGTH=8192
DEVICE=cuda  # Options: cuda, cpu, mps (for Mac)
LOAD_IN_8BIT=false
LOAD_IN_4BIT=true  # Recommended: Enable for 2-3x faster inference with 75% less memory
HUGGINGFACE_TOKEN=  # Your HuggingFace API token (get it from https://huggingface.co/settings/tokens)
USE_FLASH_ATTENTION=true  # Enable Flash Attention 2 for faster inference (requires flash-attn package)
ENABLE_KV_CACHE=true  # Enable KV cache for faster generation

# Generation Settings
DEFAULT_MAX_NEW_TOKENS=512
DEFAULT_TEMPERATURE=0.7
DEFAULT_TOP_P=0.9
DEFAULT_TOP_K=50

# RAG Settings
EMBEDDING_MODEL=sentence-transformers/paraphrase-multilingual-mpnet-base-v2
CHUNK_SIZE=512
CHUNK_OVERLAP=50

# Rate Limiting
RATE_LIMIT_ENABLED=true
MAX_REQUESTS_PER_MINUTE=60

# Logging
LOG_LEVEL=INFO  # Options: DEBUG, INFO, WARNING, ERROR
LOG_FORMAT=json  # Options: json, text
